{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data.  \n",
    "\n",
    "While viewing the data with Data Wrangler I notice that the data column is not the appropriate type. Therefore, while importing I will change the InvoiceDate to type datetime64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Change column type to datetime64[ns] for column: 'InvoiceDate'\n",
    "    df = df.astype({'InvoiceDate': 'datetime64[ns]'})\n",
    "    # Split the InvoiceDate column into year, month, day, and hour columns\n",
    "    return df\n",
    "\n",
    "# Loaded Excel file into dataframe\n",
    "df = pd.read_excel(r'd:\\OneDrive\\Business\\Data Science\\WS-Default\\Data\\Online Retail.xlsx')\n",
    "\n",
    "df = clean_data(df.copy())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the columns and store for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df.columns\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this describe it look as if there are order cancellations due to the negative values in the Quantity column. Also, there may be some errors in the pricing of some units as there are more negative values in UnitPrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check of Dtypes and also looking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are definitely some null, let's make it easier to see.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to look to see if these missing values are distributed evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the missing CustomerID values are randomly distributed throughout the data. I'm going to separate it from the main data into a separate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomerID_null = df[df['CustomerID'].isnull()]\n",
    "CustomerID_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv for safe keeping\n",
    "CustomerID_null.to_csv('CustomerID_null.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing CustomerID\n",
    "df = df.dropna(subset=['CustomerID'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck missing values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that CustomerID is stored as a float64. However, looks like CustomerID should be int32 as it's more of a category that a number.  \n",
    "\n",
    "I will check to see if there are any numbers after the decimal. If not, then I will change the dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions, _ = np.modf(df['CustomerID'])\n",
    "has_decimal = fractions != 0\n",
    "has_decimal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CustomerID'] = df['CustomerID'].astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where we now stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnitPrice negative values disapeared with the removal of CustomerID NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantity negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_quantity = df[df['Quantity'] < 0]\n",
    "neg_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to export this to a cvs file for safe keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_quantity.to_csv('neg_quantity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Quantity'] >= 0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed some product descriptions when I looked at the neg_quantity dataframe. Let's look at all the descriptions with 2 words and fewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_small = df[df['Description'].str.count(' ') < 2]\n",
    "look_des_small = des_small['Description'].value_counts()\n",
    "look_des_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be a quite a few entries that are not products. I will remove and store them in a separate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonproducts = df[df['Description'].isin(['POSTAGE', 'Manual', 'Bank Charges', 'DOTCOM POSTAGE'])]\n",
    "nonproducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonproducts.to_csv('nonproducts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Description'].isin(['POSTAGE', 'Manual', 'Bank Charges', 'DOTCOM POSTAGE'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where we stand now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are some extreme outliers. I will take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_outlier = df[df['Quantity'] > 100]\n",
    "df_q_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now compare this dataframe to the neg_quantity dataframe for possible canceled orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_quantity['Quantity'] = neg_quantity['Quantity'].abs()\n",
    "\n",
    "df_q_outlier['MATCH'] = (df_q_outlier['StockCode'].isin(neg_quantity['StockCode']) &\n",
    "                        df_q_outlier['Quantity'].isin(neg_quantity['Quantity']))\n",
    "\n",
    "df_q_outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelled_orders = df_q_outlier[df_q_outlier['MATCH']]\n",
    "\n",
    "cancelled_orders = cancelled_orders.drop('MATCH', axis=1)\n",
    "\n",
    "cancelled_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(cancelled_orders.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we've knocked out a good portion of outliers as cancelled orders. But there is still a large quantity order remaining. I will see if that order was in the df_q_outlier dataframe and if it was a cancelled order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_q_outlier[df_q_outlier['Quantity'] == 12540])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, a price of 0.0. Maybe it was a free giveaway. Or a pricing error that was exploited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that UnitPrice seems reasonable now that we've filtered out non-products and cancelled orders. But let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u_outlier = df[df['UnitPrice'] > 100]\n",
    "df_u_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the end of the cleaning portion. \n",
    "### I'll export the result to be used in further analysis and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
