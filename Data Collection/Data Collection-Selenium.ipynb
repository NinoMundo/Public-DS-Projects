{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1623d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, NoSuchWindowException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169e910",
   "metadata": {},
   "source": [
    "Read all the problem statements, notes carefully and scrape the required data using any web scraping tool of your choice.  \n",
    "• You have to handle commonly occurring EXCEPTIONS by using exception handling programing. To get information about selenium Exceptions. You may visit following links:  \n",
    "1. https://selenium-python.readthedocs.io/api.html  \n",
    "2. https://www.guru99.com/exception-handling-selenium.html  \n",
    "3. https://stackoverflow.com/questions/38022658/selenium-python-handling-no-such-elementexception/38023345  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51345c52",
   "metadata": {},
   "source": [
    "# Request 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047b11a",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia.  \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos  \n",
    "You need to find following details:  \n",
    "A) Rank  \n",
    "B) Name  \n",
    "C) Artist  \n",
    "D) Upload date  \n",
    "E) Views  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be88c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28b931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "rank = []\n",
    "name = []\n",
    "artist = []\n",
    "upload_date = []\n",
    "views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeda25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = driver.find_element(By.XPATH, \"//table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d10d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Viewed Videos\n",
    "videos_table = all_tables.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter']\")\n",
    "    \n",
    "for video_table in videos_table[0:1]:\n",
    "        video_details = video_table.find_elements(By.XPATH, \".//tbody//tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d67fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in video_details:\n",
    "    try:\n",
    "        rank.append(video.find_element(By.XPATH, \".//td[1]\").text.replace(\".\", \"\"))\n",
    "    except NoSuchElementException:\n",
    "        rank.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        name.append(video.find_element(By.XPATH, \".//td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        name.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        artist.append(video.find_element(By.XPATH, \".//td[3]\").text)\n",
    "    except NoSuchElementException:\n",
    "        artist.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        upload_date.append(video.find_element(By.XPATH, \".//td[5]\").text)\n",
    "    except NoSuchElementException:\n",
    "        upload_date.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        views.append(video.find_element(By.XPATH, \".//td[4]\").text)\n",
    "    except NoSuchElementException:\n",
    "        views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc08904c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Phonics Song with Two Words\"[26]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Sorry\"[41]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Thinking Out Loud\"[43]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Dark Horse\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[46]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Faded\"[47]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Girls Like You\"[50]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[51]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0     1                            \"Baby Shark Dance\"[6]   \n",
       "1     2                                   \"Despacito\"[9]   \n",
       "2     3                       \"Johny Johny Yes Papa\"[16]   \n",
       "3     4                                  \"Bath Song\"[17]   \n",
       "4     5                               \"Shape of You\"[18]   \n",
       "5     6                              \"See You Again\"[21]   \n",
       "6     7                \"Phonics Song with Two Words\"[26]   \n",
       "7     8                          \"Wheels on the Bus\"[27]   \n",
       "8     9                                \"Uptown Funk\"[28]   \n",
       "9    10  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10   11                              \"Gangnam Style\"[30]   \n",
       "11   12   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12   13                             \"Dame Tu Cosita\"[36]   \n",
       "13   14                                     \"Axel F\"[37]   \n",
       "14   15                                      \"Sugar\"[38]   \n",
       "15   16                                       \"Roar\"[39]   \n",
       "16   17                             \"Counting Stars\"[40]   \n",
       "17   18                                      \"Sorry\"[41]   \n",
       "18   19                        \"Baa Baa Black Sheep\"[42]   \n",
       "19   20                          \"Thinking Out Loud\"[43]   \n",
       "20   21           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "21   22                                 \"Dark Horse\"[45]   \n",
       "22   23                             \"Lakdi Ki Kathi\"[46]   \n",
       "23   24                                      \"Faded\"[47]   \n",
       "24   25                                    \"Perfect\"[48]   \n",
       "25   26                                 \"Let Her Go\"[49]   \n",
       "26   27                             \"Girls Like You\"[50]   \n",
       "27   28          \"Humpty the train on a fruits ride\"[51]   \n",
       "28   29                                    \"Lean On\"[52]   \n",
       "29   30                                   \"Bailando\"[53]   \n",
       "\n",
       "                                           Artist        Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                     Crazy Frog      June 16, 2009   \n",
       "14                                       Maroon 5   January 14, 2015   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "19                                     Ed Sheeran    October 7, 2014   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                   Jingle Toons      June 14, 2018   \n",
       "23                                    Alan Walker   December 3, 2015   \n",
       "24                                     Ed Sheeran   November 9, 2017   \n",
       "25                                      Passenger      July 25, 2012   \n",
       "26                                       Maroon 5       May 31, 2018   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "28                                    Major Lazer     March 22, 2015   \n",
       "29                               Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Views (billions)  \n",
       "0             12.85  \n",
       "1              8.16  \n",
       "2              6.70  \n",
       "3              6.20  \n",
       "4              6.00  \n",
       "5              5.89  \n",
       "6              5.30  \n",
       "7              5.24  \n",
       "8              4.92  \n",
       "9              4.89  \n",
       "10             4.80  \n",
       "11             4.55  \n",
       "12             4.35  \n",
       "13             3.91  \n",
       "14             3.87  \n",
       "15             3.80  \n",
       "16             3.79  \n",
       "17             3.66  \n",
       "18             3.64  \n",
       "19             3.60  \n",
       "20             3.59  \n",
       "21             3.52  \n",
       "22             3.48  \n",
       "23             3.45  \n",
       "24             3.45  \n",
       "25             3.44  \n",
       "26             3.42  \n",
       "27             3.41  \n",
       "28             3.38  \n",
       "29             3.38  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df = pd.DataFrame({'Rank': rank, 'Name': name, 'Artist': artist, 'Upload Date': upload_date, 'Views (billions)': views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b38152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c64d7d",
   "metadata": {},
   "source": [
    "# Request 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7fe36",
   "metadata": {},
   "source": [
    "Scrape the details team India’s international fixtures from bcci.tv.  \n",
    "Url = https://www.bcci.tv/.  \n",
    "You need to find following details:  \n",
    "A) Match title (I.e. 1st ODI)  \n",
    "B) Series  \n",
    "C) Place  \n",
    "D) Date  \n",
    "E) Time  \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b485ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eabf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to Team India’s International Fixtures page\n",
    "driver.find_element(By.XPATH, \"//ul[@class='nav navbar-nav  align-items-center']//li[@class='nav-item']//a[text()='INTERNATIONAL']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71931d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "title = []\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f76587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_168\")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_table = driver.find_element(By.XPATH, \"//div[@class='fixture-tab-inner row']\")\n",
    "matches_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5e6964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_169\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_170\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_171\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_164\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_172\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_173\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_166\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3a856bcc8c73ed51963fe5c0b4f94a5\", element=\"FDA8C36C550F8D24CBBA9A27DE181BDD_element_174\")>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_details = matches_table.find_elements(By.XPATH, \".//div[@class='col-lg-4 col-md-6 col-sm-12 ng-scope']\")\n",
    "matches_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46729e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in matches_details:\n",
    "    matchTitle = \"\"\n",
    "    \n",
    "    try:\n",
    "        matchTitle = match.find_element(By.XPATH, \".//*[@class='matchOrderText ng-binding ng-scope']\").text\n",
    "        title.append(matchTitle.replace(\"-\", \"\"))\n",
    "    except NoSuchElementException:\n",
    "        title.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        series.append(match.find_element(By.XPATH, \".//h5[@class='match-tournament-name ng-binding']\").text)\n",
    "    except NoSuchElementException:\n",
    "        series.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        place.append(match.find_element(By.XPATH, \".//*[@class='ng-binding ng-scope']\").text)\n",
    "    except NoSuchElementException:\n",
    "        place.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        date.append(match.find_element(By.XPATH, \".//div[@class='match-dates ng-binding']\").text)\n",
    "    except NoSuchElementException:\n",
    "        date.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        time_.append(match.find_element(By.XPATH, \".//div[@class='match-time no-margin ng-binding']\").text)\n",
    "    except NoSuchElementException:\n",
    "        time_.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16faa94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>9 JUL 2023</td>\n",
       "      <td>4:00 AM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>11 JUL 2023</td>\n",
       "      <td>4:00 AM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Windsor Park,</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>10:00 AM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>13 JUL 2023</td>\n",
       "      <td>4:00 AM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>15 JUL 2023</td>\n",
       "      <td>11:30 PM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>18 JUL 2023</td>\n",
       "      <td>11:30 PM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Queen's Park Oval,</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>10:00 AM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>21 JUL 2023</td>\n",
       "      <td>11:30 PM EDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                               Series  \\\n",
       "0   1st T20I   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "1   2nd T20I   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "2   1st Test        INDIA TOUR OF WEST INDIES 2023   \n",
       "3   3rd T20I   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "4    1st ODI   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "5    2nd ODI   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "6   2nd Test        INDIA TOUR OF WEST INDIES 2023   \n",
       "7    3rd ODI   INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "\n",
       "                                    Place         Date          Time  \n",
       "0  Shere Bangla National Stadium, Mirpur,   9 JUL 2023   4:00 AM EDT  \n",
       "1  Shere Bangla National Stadium, Mirpur,  11 JUL 2023   4:00 AM EDT  \n",
       "2                           Windsor Park,  12 JUL 2023  10:00 AM EDT  \n",
       "3  Shere Bangla National Stadium, Mirpur,  13 JUL 2023   4:00 AM EDT  \n",
       "4  Shere Bangla National Stadium, Mirpur,  15 JUL 2023  11:30 PM EDT  \n",
       "5  Shere Bangla National Stadium, Mirpur,  18 JUL 2023  11:30 PM EDT  \n",
       "6                      Queen's Park Oval,  20 JUL 2023  10:00 AM EDT  \n",
       "7  Shere Bangla National Stadium, Mirpur,  21 JUL 2023  11:30 PM EDT  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df = pd.DataFrame({'Match Title': title, 'Series': series, 'Place': place, 'Date': date, 'Time': time_})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10281731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea78b0",
   "metadata": {},
   "source": [
    "# Request 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783e8d4",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.  \n",
    "Url = http://statisticstimes.com/  \n",
    "You have to find following details:  \n",
    "A) Rank  \n",
    "B) State  \n",
    "C) GSDP(18-19)- at current prices  \n",
    "D) GSDP(19-20)- at current prices  \n",
    "E) Share(18-19)  \n",
    "F) GDP($ billion)  \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f18c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1902a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#object of ActionChains\n",
    "a = ActionChains(driver)\n",
    "\n",
    "#identify element (Select menu-item 'Economy')\n",
    "m = driver.find_element(By.XPATH, \"//div[@class='navbar']//div[@class='dropdown'][2]//button[@class='dropbtn']\")\n",
    "\n",
    "#hover over element\n",
    "a.move_to_element(m).perform()\n",
    "time.sleep(1)\n",
    "    \n",
    "#identify sub menu element (Select submenu-item 'India')\n",
    "n = driver.find_element(By.LINK_TEXT, \"India\")\n",
    "\n",
    "# hover over element and click\n",
    "a.move_to_element(n).click().perform()\n",
    "time.sleep(1)\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH, \"//span[text()='Close']\").click()\n",
    "except NoSuchElementException:\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cf2714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to 'GDP of Indian States' for State-wise GDP of India\n",
    "driver.find_element(By.XPATH, \"//*[contains(text(), 'GDP of Indian states')]\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "gdp_table = driver.find_element(By.XPATH, \"//table[@id='table_id']\")\n",
    "gdp_details = gdp_table.find_elements(By.XPATH, \".//tbody//tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea46ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "rank = []\n",
    "state = []\n",
    "GSDP1819 = []\n",
    "GSDP1920 = []\n",
    "share1819 = []\n",
    "GDP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e79cb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gdp_state in gdp_details:\n",
    "\n",
    "    try:\n",
    "        rank.append(gdp_state.find_element(By.XPATH, \".//td[1]\").text)\n",
    "    except NoSuchElementException:\n",
    "        rank.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        state.append(gdp_state.find_element(By.XPATH, \".//td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        state.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        GSDP1819.append(gdp_state.find_element(By.XPATH, \".//td[3]\").text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP1819.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        GSDP1920.append(gdp_state.find_element(By.XPATH, \".//td[4]\").text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP1920.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        share1819.append(gdp_state.find_element(By.XPATH, \".//td[5]\").text)\n",
    "    except NoSuchElementException:\n",
    "        share1819.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        GDP.append(gdp_state.find_element(By.XPATH, \".//td[6]\").text)\n",
    "    except NoSuchElementException:\n",
    "        GDP.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "805ec78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP (19-20)</th>\n",
       "      <th>GSDP (18-19)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP ($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP (19-20) GSDP (18-19)   Share  \\\n",
       "0     1                Maharashtra            -    2,632,792  13.94%   \n",
       "1     2                 Tamil Nadu    1,845,853    1,630,208   8.63%   \n",
       "2     3              Uttar Pradesh    1,687,818    1,584,764   8.39%   \n",
       "3     4                    Gujarat            -    1,502,899   7.96%   \n",
       "4     5                  Karnataka    1,631,977    1,493,127   7.91%   \n",
       "5     6                West Bengal    1,253,832    1,089,898   5.77%   \n",
       "6     7                  Rajasthan    1,020,989      942,586   4.99%   \n",
       "7     8             Andhra Pradesh      972,782      862,957   4.57%   \n",
       "8     9                  Telangana      969,604      861,031   4.56%   \n",
       "9    10             Madhya Pradesh      906,672      809,592   4.29%   \n",
       "10   11                     Kerala            -      781,653   4.14%   \n",
       "11   12                      Delhi      856,112      774,870   4.10%   \n",
       "12   13                    Haryana      831,610      734,163   3.89%   \n",
       "13   14                      Bihar      611,804      530,363   2.81%   \n",
       "14   15                     Punjab      574,760      526,376   2.79%   \n",
       "15   16                     Odisha      521,275      487,805   2.58%   \n",
       "16   17                      Assam            -      315,881   1.67%   \n",
       "17   18               Chhattisgarh      329,180      304,063   1.61%   \n",
       "18   19                  Jharkhand      328,598      297,204   1.57%   \n",
       "19   20                Uttarakhand            -      245,895   1.30%   \n",
       "20   21            Jammu & Kashmir            -      155,956   0.83%   \n",
       "21   22           Himachal Pradesh      165,472      153,845   0.81%   \n",
       "22   23                        Goa       80,449       73,170   0.39%   \n",
       "23   24                    Tripura       55,984       49,845   0.26%   \n",
       "24   25                 Chandigarh            -       42,114   0.22%   \n",
       "25   26                 Puducherry       38,253       34,433   0.18%   \n",
       "26   27                  Meghalaya       36,572       33,481   0.18%   \n",
       "27   28                     Sikkim       32,496       28,723   0.15%   \n",
       "28   29                    Manipur       31,790       27,870   0.15%   \n",
       "29   30                   Nagaland            -       27,283   0.14%   \n",
       "30   31          Arunachal Pradesh            -       24,603   0.13%   \n",
       "31   32                    Mizoram       26,503       22,287   0.12%   \n",
       "32   33  Andaman & Nicobar Islands            -            -       -   \n",
       "\n",
       "   GDP ($billion)  \n",
       "0         399.921  \n",
       "1         247.629  \n",
       "2         240.726  \n",
       "3         228.290  \n",
       "4         226.806  \n",
       "5         165.556  \n",
       "6         143.179  \n",
       "7         131.083  \n",
       "8         130.791  \n",
       "9         122.977  \n",
       "10        118.733  \n",
       "11        117.703  \n",
       "12        111.519  \n",
       "13         80.562  \n",
       "14         79.957  \n",
       "15         74.098  \n",
       "16         47.982  \n",
       "17         46.187  \n",
       "18         45.145  \n",
       "19         37.351  \n",
       "20         23.690  \n",
       "21         23.369  \n",
       "22         11.115  \n",
       "23          7.571  \n",
       "24          6.397  \n",
       "25          5.230  \n",
       "26          5.086  \n",
       "27          4.363  \n",
       "28          4.233  \n",
       "29          4.144  \n",
       "30          3.737  \n",
       "31          3.385  \n",
       "32              -  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df = pd.DataFrame({'Rank': rank, 'State': state, 'GSDP (19-20)': GSDP1819, 'GSDP (18-19)': GSDP1920, 'Share': share1819, 'GDP ($billion)': GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "194f2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594fa2d",
   "metadata": {},
   "source": [
    "# Request 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889723e",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com.  \n",
    "Url = https://github.com/  \n",
    "You have to find the following details:  \n",
    "A) Repository title  \n",
    "B) Repository description  \n",
    "C) Contributors count  \n",
    "D) Language used  \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a39aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd7a3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#object of ActionChains\n",
    "a = ActionChains(driver)\n",
    "\n",
    "#identify element (Select menu-item 'Explore')\n",
    "m = driver.find_element(By.XPATH, \"//*[contains(text(), 'Open Source')]\")\n",
    "\n",
    "#hover over element\n",
    "a.move_to_element(m).perform()\n",
    "time.sleep(1)\n",
    "\n",
    "#identify sub menu element (Select submenu-item 'Trending')\n",
    "n = driver.find_element(By.LINK_TEXT, \"Trending\")\n",
    "\n",
    "# hover over element and click\n",
    "a.move_to_element(n).click().perform()\n",
    "time.sleep(1)\n",
    "\n",
    "repo_details = driver.find_elements(By.XPATH, \"//article[@class='Box-row']\")\n",
    "#print(\"repo_details: \", len(repo_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e35ff56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "repo_title = []\n",
    "repo_desc = []\n",
    "cont_count = []\n",
    "language = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "942a5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in repo_details:\n",
    "\n",
    "    try:\n",
    "        repo_title.append(repo.find_element(By.XPATH, \".//h1[@class='h3 lh-condensed']//a\").text)\n",
    "    except NoSuchElementException:\n",
    "        repo_title.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        repo_desc.append(repo.find_element(By.XPATH, \".//p\").text)\n",
    "    except NoSuchElementException:\n",
    "        repo_desc.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        cont_counts = repo.find_elements(By.XPATH, \".//span[@class='d-inline-block mr-3']//a\")\n",
    "        cont_count.append(len(cont_counts))\n",
    "    except NoSuchElementException:\n",
    "        cont_count.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        language.append(repo.find_element(By.XPATH, \".//span[@itemprop='programmingLanguage']\").text)\n",
    "    except NoSuchElementException:\n",
    "        language.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4d5b7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>Official Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>Fast Segment Anything</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>GPT 3.5/4 with a Chat Web UI. No API key requi...</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>Framework to easily create LLM powered bots ov...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>Spacedrive is an open source cross-platform fi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>OpenResume is a powerful open-source resume bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-</td>\n",
       "      <td>An open source e-commerce skateshop build with...</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-</td>\n",
       "      <td>24 Lessons, 12 Weeks, Get Started as a Web Dev...</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>A DIY navigation device for Fusion360</td>\n",
       "      <td>1</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>ChatGLM-6B: An Open Bilingual Dialogue Languag...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>Code Repository for CVPR 2023 Paper \"PanoHead:...</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-</td>\n",
       "      <td>🚀✨ Help beginners to contribute to open source...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-</td>\n",
       "      <td>A local-first personal finance system</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-</td>\n",
       "      <td>The official gpt4free repository | various col...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>Cybernetically enhanced web apps</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-</td>\n",
       "      <td>Unofficial Implementation of DragGAN - \"Drag Y...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-</td>\n",
       "      <td>[CVPR 2023 Best Paper] Planning-oriented Auton...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-</td>\n",
       "      <td>QGIS is a free, open source, cross platform (l...</td>\n",
       "      <td>5</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-</td>\n",
       "      <td>🔥 🔥 🔥 An intelligent and versatile general-pur...</td>\n",
       "      <td>5</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-</td>\n",
       "      <td>PyGWalker: Turn your pandas dataframe into a T...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td>Tensor library for machine learning</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-</td>\n",
       "      <td>🧠 Dump all your files and thoughts into your p...</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Repository Title                             Repository Description  \\\n",
       "0                 -          Official Code for DragGAN (SIGGRAPH 2023)   \n",
       "1                 -  ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语...   \n",
       "2                 -                              Fast Segment Anything   \n",
       "3                 -  GPT 3.5/4 with a Chat Web UI. No API key requi...   \n",
       "4                 -  Framework to easily create LLM powered bots ov...   \n",
       "5                 -  Spacedrive is an open source cross-platform fi...   \n",
       "6                 -  OpenResume is a powerful open-source resume bu...   \n",
       "7                 -  Papers from the computer science community to ...   \n",
       "8                 -  An open source e-commerce skateshop build with...   \n",
       "9                 -  24 Lessons, 12 Weeks, Get Started as a Web Dev...   \n",
       "10                -              A DIY navigation device for Fusion360   \n",
       "11                -  ChatGLM-6B: An Open Bilingual Dialogue Languag...   \n",
       "12                -  Code Repository for CVPR 2023 Paper \"PanoHead:...   \n",
       "13                -                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。   \n",
       "14                -  🚀✨ Help beginners to contribute to open source...   \n",
       "15                -              A local-first personal finance system   \n",
       "16                -  The official gpt4free repository | various col...   \n",
       "17                -                   Cybernetically enhanced web apps   \n",
       "18                -  Unofficial Implementation of DragGAN - \"Drag Y...   \n",
       "19                -  [CVPR 2023 Best Paper] Planning-oriented Auton...   \n",
       "20                -  QGIS is a free, open source, cross platform (l...   \n",
       "21                -  🔥 🔥 🔥 An intelligent and versatile general-pur...   \n",
       "22                -  PyGWalker: Turn your pandas dataframe into a T...   \n",
       "23                -                Tensor library for machine learning   \n",
       "24                -  🧠 Dump all your files and thoughts into your p...   \n",
       "\n",
       "    Contributors Count Language Used  \n",
       "0                    5        Python  \n",
       "1                    5        Python  \n",
       "2                    5        Python  \n",
       "3                    3        Python  \n",
       "4                    5        Python  \n",
       "5                    5          Rust  \n",
       "6                    1    TypeScript  \n",
       "7                    5         Shell  \n",
       "8                    5    TypeScript  \n",
       "9                    5    JavaScript  \n",
       "10                   1           C++  \n",
       "11                   5        Python  \n",
       "12                   1        Python  \n",
       "13                   5             -  \n",
       "14                   5             -  \n",
       "15                   5    JavaScript  \n",
       "16                   5        Python  \n",
       "17                   5    JavaScript  \n",
       "18                   5        Python  \n",
       "19                   5        Python  \n",
       "20                   5           C++  \n",
       "21                   5          Java  \n",
       "22                   5        Python  \n",
       "23                   5             C  \n",
       "24                   5    TypeScript  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all data in 1 table\n",
    "df = pd.DataFrame({'Repository Title': repo_title, 'Repository Description': repo_desc, 'Contributors Count': cont_count, 'Language Used': language})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "884b2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489eafe7",
   "metadata": {},
   "source": [
    "# Request 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d223c29",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billiboard.com.  \n",
    "Url = https:/www.billboard.com/  \n",
    "You have to find the following details:  \n",
    "A) Song name  \n",
    "B) Artist name  \n",
    "C) Last week rank  \n",
    "D) Peak rank  \n",
    "E) Weeks on board  \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08033222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bb349ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Go to 'Charts'\n",
    "driver.find_element(By.XPATH, \"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d0189de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to 'Hot 100' for Top 100 Songs List\n",
    "driver.find_element(By.XPATH, \"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7be90889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "song = []\n",
    "artist = []\n",
    "last_week = []\n",
    "peak = []\n",
    "weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81d49805",
   "metadata": {},
   "outputs": [],
   "source": [
    "topSongs_details = driver.find_elements(By.XPATH, \"//div[@class='o-chart-results-list-row-container']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47e0d1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topSongs_details:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"topSongs_details: \", len(topSongs_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5d47556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topSong in topSongs_details:\n",
    "\n",
    "    try:\n",
    "        song.append(topSong.find_element(By.XPATH, \".//li[@class='lrv-u-width-100p']//ul//li[1]//h3[@id='title-of-a-story']\").text)\n",
    "    except NoSuchElementException:\n",
    "        song.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        artist.append(topSong.find_element(By.XPATH, \".//li[@class='lrv-u-width-100p']//ul//li[1]//span\").text)\n",
    "    except NoSuchElementException:\n",
    "        artist.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        last_week.append(topSong.find_element(By.XPATH, \".//li[@class='lrv-u-width-100p']//ul//li[4]\").text)\n",
    "    except NoSuchElementException:\n",
    "        last_week.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        peak.append(topSong.find_element(By.XPATH, \".//li[@class='lrv-u-width-100p']//ul//li[5]\").text)\n",
    "    except NoSuchElementException:\n",
    "        peak.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        weeks_on_board.append(topSong.find_element(By.XPATH, \".//li[@class='lrv-u-width-100p']//ul//li[6]\").text)\n",
    "    except NoSuchElementException:\n",
    "        weeks_on_board.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "729af1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Angel, Pt. 1</td>\n",
       "      <td>Kodak Black, NLE Choppa, Jimin, JVKE &amp; Muni Long</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>Parmalee</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Moonlight</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Classy 101</td>\n",
       "      <td>Feid x Young Miko</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bluffin</td>\n",
       "      <td>Gucci Mane &amp; Lil Baby</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song Name                                       Artist Name  \\\n",
       "0     Last Night                                     Morgan Wallen   \n",
       "1       Fast Car                                        Luke Combs   \n",
       "2      Calm Down                               Rema & Selena Gomez   \n",
       "3        Flowers                                       Miley Cyrus   \n",
       "4    All My Life                        Lil Durk Featuring J. Cole   \n",
       "..           ...                                               ...   \n",
       "95  Angel, Pt. 1  Kodak Black, NLE Choppa, Jimin, JVKE & Muni Long   \n",
       "96  Girl In Mine                                          Parmalee   \n",
       "97     Moonlight                                        Kali Uchis   \n",
       "98    Classy 101                                 Feid x Young Miko   \n",
       "99       Bluffin                             Gucci Mane & Lil Baby   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks On Board  \n",
       "0               1         1             21  \n",
       "1               3         2             13  \n",
       "2               4         3             42  \n",
       "3               2         1             23  \n",
       "4               5         2              6  \n",
       "..            ...       ...            ...  \n",
       "95              -        65              2  \n",
       "96              -        97              1  \n",
       "97             90        80             11  \n",
       "98              -        99              1  \n",
       "99              -       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all data in 1 table\n",
    "df = pd.DataFrame({'Song Name': song, 'Artist Name': artist, 'Last Week Rank': last_week, 'Peak Rank': peak, 'Weeks On Board': weeks_on_board})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79af4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60537d",
   "metadata": {},
   "source": [
    "# Request 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e189fc",
   "metadata": {},
   "source": [
    "Scrape the details of Highest sellingnovels.  \n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare  \n",
    "You have to find the following details:  \n",
    "A) Book name  \n",
    "B) Author name  \n",
    "C) Volumes sold  \n",
    "D) Publisher  \n",
    "E) Genre  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a7a9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b63e7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_table = driver.find_element(By.XPATH, \"//table[@class='in-article sortable']\")\n",
    "novels_details = novels_table.find_elements(By.XPATH, \".//tbody//tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60e221d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "book = []\n",
    "author = []\n",
    "sold = []\n",
    "publisher = []\n",
    "genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2196365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for novel in novels_details:\n",
    "\n",
    "    try:\n",
    "        book.append(novel.find_element(By.XPATH, \".//td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        book.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        author.append(novel.find_element(By.XPATH, \".//td[3]\").text)\n",
    "    except NoSuchElementException:\n",
    "        author.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        sold.append(novel.find_element(By.XPATH, \".//td[4]\").text)\n",
    "    except NoSuchElementException:\n",
    "        sold.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        publisher.append(novel.find_element(By.XPATH, \".//td[5]\").text)\n",
    "    except NoSuchElementException:\n",
    "        publisher.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        genre.append(novel.find_element(By.XPATH, \".//td[6]\").text)\n",
    "    except NoSuchElementException:\n",
    "        genre.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80fb9439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df = pd.DataFrame({'Book Name': book, 'Author Name': author, 'Volumes Sold': sold, 'Publisher': publisher, 'Genre': genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b48d1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f01965",
   "metadata": {},
   "source": [
    "# Request 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fd638",
   "metadata": {},
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com.  \n",
    "Url = https://www.imdb.com/list/ls095964455/  \n",
    "You have to find the following details:  \n",
    "A) Name  \n",
    "B) Year span  \n",
    "C) Genre  \n",
    "D) Run time  \n",
    "E) Ratings  \n",
    "F) Votes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb65db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fb48ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvShows = driver.find_elements(By.XPATH, \"//div[@class='lister-item mode-detail']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "781f93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "name = []\n",
    "years = []\n",
    "genre = []\n",
    "run_time = []\n",
    "rating = []\n",
    "votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "082990c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tvShow in tvShows:\n",
    "\n",
    "    try:\n",
    "        name.append(tvShow.find_element(By.XPATH, \".//h3[@class='lister-item-header']//a\").text)\n",
    "    except NoSuchElementException:\n",
    "        name.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        years.append(tvShow.find_element(By.XPATH, \".//span[@class='lister-item-year text-muted unbold']\").text)\n",
    "    except NoSuchElementException:\n",
    "        years.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        genre.append(tvShow.find_element(By.XPATH, \".//p[@class='text-muted text-small']//span[@class='genre']\").text)\n",
    "    except NoSuchElementException:\n",
    "        genre.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        run_time.append(tvShow.find_element(By.XPATH, \".//p[@class='text-muted text-small']//span[@class='runtime']\").text)\n",
    "    except NoSuchElementException:\n",
    "        run_time.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        rating.append(tvShow.find_element(By.XPATH, \".//span[@class='ipl-rating-star__rating']\").text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"-\")\n",
    "\n",
    "    try:\n",
    "        votes.append(tvShow.find_element(By.XPATH, \".//span[@name='nv']\").text)\n",
    "    except NoSuchElementException:\n",
    "        votes.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3c04207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,173,688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,251,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,032,482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>43,401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>260,195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Rating      Votes  \n",
       "0    57 min    9.2  2,173,688  \n",
       "1    51 min    8.7  1,251,525  \n",
       "2    44 min    8.1  1,032,482  \n",
       "3    60 min    7.5    303,555  \n",
       "4    43 min    7.6    262,726  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.4     51,956  \n",
       "96   50 min    7.8     63,993  \n",
       "97   42 min    8.1    208,541  \n",
       "98   45 min    7.1     43,401  \n",
       "99  572 min    8.6    260,195  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df = pd.DataFrame({'Name': name, 'Year Span': years, 'Genre': genre, 'Run Time': run_time, 'Rating': rating, 'Votes': votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e914d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66e60c",
   "metadata": {},
   "source": [
    "# Request 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1568a",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories.  \n",
    "Url = https://archive.ics.uci.edu/  \n",
    "You have to find the following details:  \n",
    "A) Dataset name  \n",
    "B) Data type  \n",
    "C) Task  \n",
    "D) Attribute type  \n",
    "E) No of instances  \n",
    "F) No of attribute  \n",
    "G) Year  \n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6739a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13c223d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/div/div[2]/button').click()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]').click()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35cb6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "dataset = []\n",
    "data_type = []\n",
    "task = []\n",
    "attribute_type = []\n",
    "instance_number = []\n",
    "year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd36d2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true = True\n",
    "\n",
    "while true:\n",
    "\n",
    "    datasets = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/h2/a')\n",
    "    for i in datasets:\n",
    "        datase = i.text\n",
    "        dataset.append(datase)\n",
    "\n",
    "    data_types = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/div/div[2]/span')\n",
    "    for i in data_types:\n",
    "        data_ty = i.text\n",
    "        if len(data_ty) < 1:\n",
    "            data_ty = '-'\n",
    "        data_type.append(data_ty)\n",
    "\n",
    "    tasks = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/div/div[1]/span')\n",
    "    for i in tasks:\n",
    "        tas = i.text\n",
    "        if len(tas) < 1:\n",
    "            tas = '-'\n",
    "        task.append(tas)\n",
    "\n",
    "    attribute_types = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "    for i in attribute_types:\n",
    "        attribute_ty = i.text\n",
    "        if len(attribute_ty) < 1:\n",
    "            attribute_ty = '-'\n",
    "        attribute_type.append(attribute_ty)\n",
    "\n",
    "    instance_numbers = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/div/div[3]/span')\n",
    "    for i in instance_numbers:\n",
    "        instance_num = i.text\n",
    "        if len(instance_num) < 1:\n",
    "            instance_num = '-'\n",
    "        instance_number.append(instance_num)\n",
    "        \n",
    "    years = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "    for i in years:\n",
    "        yea = i.text\n",
    "        year.append(yea)  \n",
    "\n",
    "    try:    \n",
    "        driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]').click() \n",
    "    except:\n",
    "        true = 0\n",
    "        break\n",
    "    \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1b9197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>PMU-UD</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>5.18K Instances</td>\n",
       "      <td>8/4/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>chestnut â€“ LARVIC</td>\n",
       "      <td>null</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>1.45K Instances</td>\n",
       "      <td>5/29/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>EBL Domain Theories</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Moral Reasoner</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>N/A</td>\n",
       "      <td>202 Instances</td>\n",
       "      <td>5/31/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>DGP2 - The Second Data Generation Program</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>-</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DataSet Name     Data Type  \\\n",
       "0                                         Iris  Multivariate   \n",
       "1                                Heart Disease  Multivariate   \n",
       "2                                        Adult  Multivariate   \n",
       "3                             Dry Bean Dataset  Multivariate   \n",
       "4                                     Diabetes             -   \n",
       "..                                         ...           ...   \n",
       "618                                     PMU-UD    Univariate   \n",
       "619                        chestnut â€“ LARVIC          null   \n",
       "620                        EBL Domain Theories             -   \n",
       "621                             Moral Reasoner             -   \n",
       "622  DGP2 - The Second Data Generation Program             -   \n",
       "\n",
       "                           Task              Attribute Type   No of Instances  \\\n",
       "0                Classification                        Real     150 Instances   \n",
       "1                Classification  Categorical, Integer, Real     303 Instances   \n",
       "2                Classification        Categorical, Integer  48.84K Instances   \n",
       "3                Classification               Integer, Real  13.61K Instances   \n",
       "4                             -        Categorical, Integer                 -   \n",
       "..                          ...                         ...               ...   \n",
       "618              Classification                           -   5.18K Instances   \n",
       "619  Classification, Clustering                           -   1.45K Instances   \n",
       "620                           -                         N/A                 -   \n",
       "621                           -                         N/A     202 Instances   \n",
       "622                           -                        Real                 -   \n",
       "\n",
       "          Year  \n",
       "0    6/30/1988  \n",
       "1    6/30/1988  \n",
       "2    4/30/1996  \n",
       "3    9/13/2020  \n",
       "4          N/A  \n",
       "..         ...  \n",
       "618   8/4/2018  \n",
       "619  5/29/2017  \n",
       "620        N/A  \n",
       "621  5/31/1994  \n",
       "622        N/A  \n",
       "\n",
       "[623 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'DataSet Name': dataset, 'Data Type': data_type, 'Task': task, 'Attribute Type': attribute_type, 'No of Instances': instance_number, 'Year': year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "331c1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b08cdf",
   "metadata": {},
   "source": [
    "# Request 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2696b5",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters  \n",
    "Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details:  \n",
    "A) Name  \n",
    "B) Designation  \n",
    "C)Company  \n",
    "D)Skills they hire for  \n",
    "E) Location  \n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type \"Data science\" and click on search. All this should be done through code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c7204ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the driver\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(\"https://www.naukri.com/hr-recruiters-consultants/\")\n",
    "\n",
    "# Data Science yields an Access Denied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2042981",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div[2]/div/button').click()\n",
    "\n",
    "element_xpath = \"/html/body/div[1]/div[4]/div/div/section/div[3]/div/a[2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "34aa79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "\n",
    "name = []\n",
    "designation = []\n",
    "company = []\n",
    "location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33ff7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(name)!=10:\n",
    "\n",
    "    element = driver.find_element(By.XPATH, element_xpath)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "    driver.execute_script(\"window.scrollBy(0, -100);\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    names = driver.find_elements(By.XPATH, \"//*[@class='title ellipsis']\")\n",
    "    for i in names:                       \n",
    "        nam = i.text\n",
    "        name.append(nam)\n",
    "\n",
    "    designations = driver.find_elements(By.XPATH,\"//*[@class='ellipsis fleft ']\")\n",
    "    for i in designations:                       \n",
    "        desig = i.text\n",
    "        designation.append(desig)\n",
    "        \n",
    "    companies = driver.find_elements(By.XPATH,\"//*[@class='subTitle ellipsis fleft']\")\n",
    "    for i in companies:                       \n",
    "        comp = i.text\n",
    "        company.append(comp)\n",
    "\n",
    "    locations = driver.find_elements(By.XPATH,\"//*[@class='ellipsis fleft locWdth']\")\n",
    "    for i in locations:                       \n",
    "        loc = i.text\n",
    "        if len(loc) < 1:\n",
    "            location.append(\"-\")\n",
    "        else:\n",
    "            location.append(loc)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section/div[3]/div/a[2]').click()\n",
    "\n",
    "# Access denied\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9193042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 19\n"
     ]
    }
   ],
   "source": [
    "print(len(name), len(designation), len(company), len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "41345393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recruitment Opportunity For HR Executive</td>\n",
       "      <td>1.25-2 Lacs PA</td>\n",
       "      <td>Kone</td>\n",
       "      <td>Chennai, Tamil Nadu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human Resources Executive</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Marriott</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR Recruiter _ Bhubaneshwar (Btech Candidates ...</td>\n",
       "      <td>1.75-2.5 Lacs PA</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR Recruitment Scheduler Specialist - Bangalore</td>\n",
       "      <td>80,000-3 Lacs PA</td>\n",
       "      <td>2coms</td>\n",
       "      <td>Bangalore/Bengaluru, Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job opportunity For freshers/HR Recruiter/HR E...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Black And White Business Solutions</td>\n",
       "      <td>Bangalore/Bengaluru(Kodihalli +3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HR Executive</td>\n",
       "      <td>4-5 Lacs PA</td>\n",
       "      <td>Bonami Software</td>\n",
       "      <td>New Delhi, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Direct Walk in Interview For HR Executive(Female)</td>\n",
       "      <td>1.25-2.25 Lacs PA</td>\n",
       "      <td>m2 Vending</td>\n",
       "      <td>Bangalore/Bengaluru(Bannerghatta +1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HR Executive</td>\n",
       "      <td>2-3 Lacs PA</td>\n",
       "      <td>Reputed Group of Higher Education Insititions....</td>\n",
       "      <td>Hybrid - Mohali, Punjab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jr HR Executive</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>SPECTRAFORCE</td>\n",
       "      <td>Mohali, Punjab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Abhinav Futuristics</td>\n",
       "      <td>Pune, Maharashtra(Koregaon Park)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Executive/ Assistant Manager HR Generalist - P...</td>\n",
       "      <td>5-6 Lacs PA</td>\n",
       "      <td>OASIS</td>\n",
       "      <td>Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Opening For Management Trainee / Executive - HR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Sahajanand Medical Technologies</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Recruiter - HR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Fashion Tv India</td>\n",
       "      <td>Bhubaneswar, Odisha, Hubli, Karnataka, Sambalp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assistant Manager - HR (Field Level Recruitment)</td>\n",
       "      <td>2.5-4 Lacs PA</td>\n",
       "      <td>Muthoot Microfin</td>\n",
       "      <td>Gurgaon/ Gurugram, Haryana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hiring Freshers : HR Executive: Recruiter-Guru...</td>\n",
       "      <td>50,000-2.5 Lacs PA</td>\n",
       "      <td>Advance Career Solutions</td>\n",
       "      <td>Navi Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HR Trainee/Fresher(MBA)-Navi Mumbai(IMD joiner...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>3i Infotech</td>\n",
       "      <td>Navi Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HR Trainee/Fresher(MBA)-Navi Mumbai(IMD joiner...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>3i Infotech</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hiring Hr recruiters, day shift, spot offer an...</td>\n",
       "      <td>2-2.5 Lacs PA</td>\n",
       "      <td>Ignites Human Capital</td>\n",
       "      <td>Jabalpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Human Resource Recruiter @Jabalpur: Salary Upt...</td>\n",
       "      <td>1-1.5 Lacs PA</td>\n",
       "      <td>KVC Consultants Ltd.</td>\n",
       "      <td>Jabalpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name         Designation  \\\n",
       "0            Recruitment Opportunity For HR Executive      1.25-2 Lacs PA   \n",
       "1                           Human Resources Executive       Not disclosed   \n",
       "2   HR Recruiter _ Bhubaneshwar (Btech Candidates ...    1.75-2.5 Lacs PA   \n",
       "3     HR Recruitment Scheduler Specialist - Bangalore    80,000-3 Lacs PA   \n",
       "4   Job opportunity For freshers/HR Recruiter/HR E...       Not disclosed   \n",
       "5                                        HR Executive         4-5 Lacs PA   \n",
       "6   Direct Walk in Interview For HR Executive(Female)   1.25-2.25 Lacs PA   \n",
       "7                                        HR Executive         2-3 Lacs PA   \n",
       "8                                     Jr HR Executive       Not disclosed   \n",
       "9                                        HR Executive       Not disclosed   \n",
       "10  Executive/ Assistant Manager HR Generalist - P...         5-6 Lacs PA   \n",
       "11    Opening For Management Trainee / Executive - HR       Not disclosed   \n",
       "12                                     Recruiter - HR       Not disclosed   \n",
       "13   Assistant Manager - HR (Field Level Recruitment)       2.5-4 Lacs PA   \n",
       "14  Hiring Freshers : HR Executive: Recruiter-Guru...  50,000-2.5 Lacs PA   \n",
       "15  HR Trainee/Fresher(MBA)-Navi Mumbai(IMD joiner...       Not disclosed   \n",
       "16  HR Trainee/Fresher(MBA)-Navi Mumbai(IMD joiner...       Not disclosed   \n",
       "17  Hiring Hr recruiters, day shift, spot offer an...       2-2.5 Lacs PA   \n",
       "18  Human Resource Recruiter @Jabalpur: Salary Upt...       1-1.5 Lacs PA   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                                Kone   \n",
       "1                                            Marriott   \n",
       "2                                       Tech Mahindra   \n",
       "3                                               2coms   \n",
       "4                  Black And White Business Solutions   \n",
       "5                                     Bonami Software   \n",
       "6                                          m2 Vending   \n",
       "7   Reputed Group of Higher Education Insititions....   \n",
       "8                                        SPECTRAFORCE   \n",
       "9                                 Abhinav Futuristics   \n",
       "10                                              OASIS   \n",
       "11                    Sahajanand Medical Technologies   \n",
       "12                                   Fashion Tv India   \n",
       "13                                   Muthoot Microfin   \n",
       "14                           Advance Career Solutions   \n",
       "15                                        3i Infotech   \n",
       "16                                        3i Infotech   \n",
       "17                              Ignites Human Capital   \n",
       "18                               KVC Consultants Ltd.   \n",
       "\n",
       "                                             Location  \n",
       "0                                 Chennai, Tamil Nadu  \n",
       "1                                             Chennai  \n",
       "2                                         Bhubaneswar  \n",
       "3                      Bangalore/Bengaluru, Bangalore  \n",
       "4                   Bangalore/Bengaluru(Kodihalli +3)  \n",
       "5                              New Delhi, Delhi / NCR  \n",
       "6                Bangalore/Bengaluru(Bannerghatta +1)  \n",
       "7                             Hybrid - Mohali, Punjab  \n",
       "8                                      Mohali, Punjab  \n",
       "9                    Pune, Maharashtra(Koregaon Park)  \n",
       "10                                 Mumbai (All Areas)  \n",
       "11                                             Mumbai  \n",
       "12  Bhubaneswar, Odisha, Hubli, Karnataka, Sambalp...  \n",
       "13                         Gurgaon/ Gurugram, Haryana  \n",
       "14                           Navi Mumbai, Maharashtra  \n",
       "15                           Navi Mumbai, Maharashtra  \n",
       "16                    Bangalore/ Bengaluru, Karnataka  \n",
       "17                                           Jabalpur  \n",
       "18                                           Jabalpur  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all data in 1 table\n",
    "df = pd.DataFrame({'Name': name[:19], 'Designation': designation[:19], 'Company': company[:19], 'Location': location[:19]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e64ad75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bc583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
